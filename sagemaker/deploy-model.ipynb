{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct the model\n",
    "\n",
    "The code below makes a simple ResNet50 model pretrained on ImageNet data.  If desired, replace this with your own model.  Note there is no training step here because the weights are already coming in pre-filled from the Keras library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def get_input_shape(w, h):\n",
    "  if tf.keras.backend.image_data_format() == 'channels_first':\n",
    "    input_shape = (3, w, h)\n",
    "  else:\n",
    "    input_shape = (w, h, 3)\n",
    "  return input_shape\n",
    "\n",
    "image_w = 224\n",
    "image_h = 224\n",
    "dropout = 0.5\n",
    "\n",
    "input_shape = get_input_shape(image_w, image_h)\n",
    "\n",
    "input_tensor = tf.keras.layers.Input(shape=input_shape)\n",
    "\n",
    "base_model = tf.keras.applications.ResNet50(\n",
    "    include_top=True,\n",
    "    weights=\"imagenet\",\n",
    "    input_tensor=input_tensor\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summarize the model and validate that it works\n",
    "\n",
    "Print a summary of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(base_model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct `x`, our NumPy array of two images to be classified by the local model.  For the test images cat & dog.jpg, just find a random picture of a cat and a dog on the Internet, preferably with roughly square aspect ratio.  For cat224 and dog224, use an image editor to size the images to 224*224 pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "import numpy as np\n",
    "\n",
    "img_path1 = 'cat224.jpg'\n",
    "img1 = image.load_img(img_path1, target_size=(224, 224))\n",
    "img_path2 = 'dog224.jpg'\n",
    "img2 = image.load_img(img_path2, target_size=(224, 224))\n",
    "x = image.img_to_array(img1)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "y = image.img_to_array(img2)\n",
    "y = np.expand_dims(y, axis=0)\n",
    "x = np.append(x, y, axis=0)\n",
    "x = preprocess_input(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform inference on at least one obvious image to make sure classification works as expected.  Here we provide images of a cat and dog at 224*224 pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = base_model.predict(x)\n",
    "# decode the results into a list of tuples (class, description, probability)\n",
    "# (one such list for each sample in the batch)\n",
    "print('Predicted:', decode_predictions(preds, top=3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the model\n",
    "\n",
    "Use the Tensorflow `save` function provided in TF2 to very simply save the base model to the desired path.  No Session needed.  The path to `export/Servo/` is required by Amazon SageMaker, and the `0000000001/` is simply a model index so that Tensorflow Serving will automatically serve the correct model version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "model_save_path = os.path.join(\"\", \"export/Servo/0000000001/\")\n",
    "tf.saved_model.save(base_model, model_save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tar & gzip the model for convenient deployment\n",
    "\n",
    "And because you have to provide a tarred Gzipped file as an argument to a function later ;)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar chvfz test-resnet50.tar.gz export/*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-import the model\n",
    "\n",
    "Do not bother uploading the SavedModel to S3 yourself.  This will only cause you much grief.  Instead, instantiate a SageMaker Session which will calculate the correct S3 bucket to use and handle everything on its own.\n",
    "\n",
    "By using the `Model` class instead of `TensorFlowModel` (as demonstrated in https://github.com/aws/amazon-sagemaker-examples/blob/master/sagemaker-python-sdk/tensorflow_serving_container/tensorflow_serving_container.ipynb ), we get support for Python 3 since it's Amazon's understanding that (even still) TensorFlow Serving API library doesn't support Python 3.  This is elaborated on if you read the GitHub issue post https://github.com/aws/sagemaker-python-sdk/issues/912#issuecomment-510226311 ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker.tensorflow.serving import Model\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "inputs = sagemaker_session.upload_data(path='test-resnet50.tar.gz', key_prefix='test-resnet50')\n",
    "\n",
    "sagemaker_model = Model(\n",
    "    model_data=inputs,\n",
    "    role='arn:aws:iam::232188586941:role/amazon-sagemaker-practice',\n",
    "    framework_version='2.2.0'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy the model onto SageMaker\n",
    "\n",
    "Note: This step takes a while, perhaps 5-10 minutes.  As it completes, you'll see dashes `-` appear in the output beneath the code cell.  These tick off every 30 seconds.  You will see a bang `!` when the deployment is completed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = sagemaker_model.deploy(initial_instance_count=1, instance_type='ml.c5.xlarge')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find the endpoint name\n",
    "\n",
    "This should be the same name for the endpoint as shown on the AWS Console, e.g. `tensorflow-inference-2020-10-27-17-54-06-462`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Invoke the SageMaker Model from Scratch\n",
    "\n",
    "If you didn't bother with any of the other steps above, and want to go straight into calling an existing SageMaker model for inference, then you need to instantiate a Predictor.  (And just to make this even weirder, it seems like this uses SageMaker V1 syntax rather than V2 syntax, but trying to import the libraries and run the code in V2 format fails on my instance.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tensorflow.serving import Predictor\n",
    "\n",
    "# Note that moving to Predictor V2 will have different defaults for\n",
    "# serializer & deserializer, which are currently both JSON in this code\n",
    "predictor = Predictor(\n",
    "    endpoint_name='tensorflow-inference-2020-10-27-17-54-06-462'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the model\n",
    "\n",
    "Toward the top of this notebook, we defined `x` as an array consisting of two pictures to classify.  Go back and run that if you haven't done it already.  We can use `x` as-is with the SageMaker endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use x from before, when constructing arrays for inception on the original Keras model loaded in memory\n",
    "result = predictor.predict(x)\n",
    "\n",
    "cat_preds = result['predictions'][0]\n",
    "cat_preds = np.expand_dims(cat_preds, axis=0)\n",
    "dog_preds = result['predictions'][1]\n",
    "dog_preds = np.expand_dims(dog_preds, axis=0)\n",
    "all_preds = np.append(cat_preds, dog_preds, axis=0)\n",
    "print(all_preds.shape)\n",
    "decode_predictions(all_preds, top=3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow2_p36",
   "language": "python",
   "name": "conda_tensorflow2_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
